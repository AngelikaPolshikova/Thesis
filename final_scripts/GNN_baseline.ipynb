{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e01899d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.data import Data\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from skimage.measure import label, regionprops\n",
    "from scipy.ndimage import median_filter\n",
    "from skimage.filters import gaussian\n",
    "from skimage import exposure\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Set config\n",
    "CONFIG = {\n",
    "    \"resize_shape\": (512, 512),\n",
    "    \"intensity_thresh\": 0.01,\n",
    "    \"lost_ttl\": 3,\n",
    "    \"max_nodes\": 100,\n",
    "    \"batch_size\": 1,\n",
    "    \"lr\": 1e-3,\n",
    "    \"num_epochs\": 100,\n",
    "    \"patience\": 10,\n",
    "    \"save_dir\": os.path.expanduser(\"~/Desktop/GNN_Predictions\")\n",
    "}\n",
    "\n",
    "os.makedirs(CONFIG[\"save_dir\"], exist_ok=True)\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3bf91aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def denoise_gaussian_median(frame, median_size=3, gaussian_sigma=1.0):\n",
    "    medianed = median_filter(frame, size=median_size)\n",
    "    smoothed = gaussian(medianed, sigma=gaussian_sigma)\n",
    "    return smoothed\n",
    "\n",
    "def apply_clahe(frame, clip_limit=0.01):\n",
    "    return exposure.equalize_adapthist(frame, clip_limit=clip_limit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aafb73f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_graph_from_frame(frame, intensity_thresh=0.01, max_nodes=100, source_idx=None):\n",
    "    binary_mask = frame > intensity_thresh\n",
    "    labeled = label(binary_mask)\n",
    "    props = regionprops(labeled, intensity_image=frame)\n",
    "\n",
    "    node_features = []\n",
    "    node_ids = []\n",
    "    for i, p in enumerate(props[:max_nodes]):\n",
    "        x, y = p.centroid[::-1]  # x = width, y = height\n",
    "        intensity = p.mean_intensity\n",
    "        node_features.append([x, y, intensity])\n",
    "        node_ids.append(i)\n",
    "\n",
    "    if len(node_features) == 0:\n",
    "        return None\n",
    "    elif len(node_features) == 1:\n",
    "        return None  # GCNConv needs at least 2 nodes\n",
    "\n",
    "    # More than 1 node\n",
    "    idx = torch.arange(len(node_features))\n",
    "    comb = torch.combinations(idx, r=2)\n",
    "    if comb.size(0) == 0:\n",
    "        return None  # No edges\n",
    "\n",
    "    edge_index = comb.T\n",
    "    edge_index = torch.cat([edge_index, edge_index.flip(0)], dim=1)\n",
    "\n",
    "    # Final validation\n",
    "    if not (edge_index.ndim == 2 and edge_index.shape[0] == 2 and edge_index.shape[1] > 0):\n",
    "        return None\n",
    "\n",
    "    x = torch.tensor(node_features, dtype=torch.float)  # Features: [x, y, intensity]\n",
    "    y = torch.tensor([f[2] for f in node_features], dtype=torch.float).view(-1, 1)  # Use intensity as label\n",
    "    positions = torch.tensor([[f[0], f[1]] for f in node_features], dtype=torch.float)\n",
    "\n",
    "    g = Data(x=x, edge_index=edge_index, y=y, pos=positions)\n",
    "    g.node_ids = torch.tensor(node_ids, dtype=torch.long)\n",
    "    return g\n",
    "\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "\n",
    "\n",
    "def build_temporal_graph_sequence(path):\n",
    "    max_nodes = CONFIG[\"max_nodes\"]\n",
    "    intensity_thresh = CONFIG[\"intensity_thresh\"]\n",
    "\n",
    "    stack = imread(path)\n",
    "    stack_denoised = np.array([denoise_gaussian_median(f, gaussian_sigma=1.0) for f in stack])\n",
    "    stack_resized = np.array([resize(f, CONFIG[\"resize_shape\"]) for f in stack_denoised])\n",
    "    norm_stack = (stack_resized - stack_resized.min()) / (stack_resized.max() - stack_resized.min())\n",
    "    norm_stack = norm_stack * 2 - 1\n",
    "\n",
    "    graphs = []\n",
    "    node_positions_per_frame = []\n",
    "\n",
    "    for frame in norm_stack:\n",
    "        binary_mask = frame > intensity_thresh\n",
    "        labeled = label(binary_mask)\n",
    "        props = regionprops(labeled, intensity_image=frame)\n",
    "\n",
    "        node_features = []\n",
    "        node_positions = []\n",
    "\n",
    "        for p in props[:max_nodes]:\n",
    "            x, y = p.centroid[::-1]\n",
    "            intensity = p.mean_intensity\n",
    "            node_features.append([x, y, intensity])\n",
    "            node_positions.append([x, y])\n",
    "\n",
    "        if len(node_features) > 1:\n",
    "            graphs.append(np.array(node_features))\n",
    "            node_positions_per_frame.append(np.array(node_positions))\n",
    "\n",
    "    aligned_graphs = []\n",
    "\n",
    "    for t in range(len(graphs) - 1):\n",
    "        current = graphs[t]\n",
    "        next_frame = graphs[t + 1]\n",
    "        pos_current = node_positions_per_frame[t]\n",
    "        pos_next = node_positions_per_frame[t + 1]\n",
    "\n",
    "        dist_matrix = cdist(pos_current, pos_next)\n",
    "        match = dist_matrix.argmin(axis=1)\n",
    "\n",
    "        matched_intensities = []\n",
    "        for i, j in enumerate(match):\n",
    "            if j < len(next_frame):\n",
    "                matched_intensities.append(next_frame[j][2])\n",
    "            else:\n",
    "                matched_intensities.append(0.0)\n",
    "\n",
    "        x = torch.tensor(current, dtype=torch.float)\n",
    "        y = torch.tensor(matched_intensities, dtype=torch.float).view(-1, 1)\n",
    "\n",
    "        idx = torch.arange(x.shape[0])\n",
    "        comb = torch.combinations(idx, r=2)\n",
    "        edge_index = comb.T\n",
    "        edge_index = torch.cat([edge_index, edge_index.flip(0)], dim=1)\n",
    "\n",
    "        pos = torch.tensor(pos_current, dtype=torch.float)\n",
    "        g = Data(x=x, edge_index=edge_index, y=y, pos=pos)\n",
    "        aligned_graphs.append(g)\n",
    "\n",
    "    return aligned_graphs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c04134e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleGraphDataset(Dataset):\n",
    "    def __init__(self, graphs):\n",
    "        # Filter out invalid graphs\n",
    "        self.graphs = [\n",
    "            g for g in graphs\n",
    "            if hasattr(g, \"edge_index\")\n",
    "            and g.edge_index is not None\n",
    "            and g.edge_index.ndim == 2\n",
    "            and g.edge_index.shape[0] == 2\n",
    "            and g.edge_index.shape[1] > 0\n",
    "        ]\n",
    "        print(f\"Using {len(self.graphs)} valid graphs after filtering.\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.graphs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.graphs[idx]  # Return the full Data object\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb79ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simple GCN Model\n",
    "\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "class StrongerGNN(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(input_dim, 64)\n",
    "        self.conv2 = GCNConv(64, 64)\n",
    "        self.conv3 = GCNConv(64, 32)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.lin = nn.Linear(32, 1)\n",
    "\n",
    "    def forward(self, x, edge_index, batch=None):\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.conv2(x, edge_index))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.conv3(x, edge_index))\n",
    "        return self.lin(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6663916b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_gnn_predictions(preds, targets, positions, shape=(128, 128), num_examples=5):\n",
    "    os.makedirs(CONFIG[\"save_dir\"], exist_ok=True)\n",
    "\n",
    "    for i in range(min(num_examples, len(positions))):  # Use only valid batches\n",
    "        pred_img = np.zeros(shape)\n",
    "        target_img = np.zeros(shape)\n",
    "        count_img = np.zeros(shape)\n",
    "\n",
    "        try:\n",
    "            for (x, y), pred, true in zip(positions[i], preds[i], targets[i]):\n",
    "                x = int(np.clip(x, 0, shape[1] - 1))  # width\n",
    "                y = int(np.clip(y, 0, shape[0] - 1))  # height\n",
    "                pred_img[y, x] += pred\n",
    "                target_img[y, x] += true\n",
    "                count_img[y, x] += 1\n",
    "        except Exception as e:\n",
    "            print(f\" Skipped batch {i} due to error: {e}\")\n",
    "            continue\n",
    "\n",
    "        # Avoid division by zero\n",
    "        count_img[count_img == 0] = 1\n",
    "        pred_img /= count_img\n",
    "        target_img /= count_img\n",
    "        diff_img = np.abs(pred_img - target_img)\n",
    "\n",
    "        fig, axs = plt.subplots(1, 3, figsize=(12, 4))\n",
    "        axs[0].imshow(target_img, cmap=\"viridis\")\n",
    "        axs[0].set_title(\"True Activation at t+1\")\n",
    "        axs[1].imshow(pred_img, cmap=\"viridis\")\n",
    "        axs[1].set_title(\"Predicted Activation at t+1\")\n",
    "        axs[2].imshow(diff_img, cmap=\"hot\")\n",
    "        axs[2].set_title(\"Prediction Error\")\n",
    "        axs[1].scatter(\n",
    "        [int(p[0]) for p in positions[i]],\n",
    "        [int(p[1]) for p in positions[i]],\n",
    "        color='white', s=10, alpha=0.5\n",
    "        )\n",
    "        for ax in axs:\n",
    "            ax.axis(\"off\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(CONFIG[\"save_dir\"], f\"GNN_Predictions_{i}.png\"))\n",
    "        plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b3170e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def train(model, loader, optimizer, loss_fn_main, loss_fn_alt):\n",
    "    model.train()\n",
    "    total_main = 0\n",
    "    total_alt = 0\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data.x, data.edge_index, data.batch)\n",
    "        loss_main = loss_fn_main(out, data.y)\n",
    "        loss_alt = loss_fn_alt(out, data.y)\n",
    "        loss_main.backward()\n",
    "        optimizer.step()\n",
    "        total_main += loss_main.item()\n",
    "        total_alt += loss_alt.item()\n",
    "    return total_main / len(loader), total_alt / len(loader)\n",
    "\n",
    "def evaluate(model, loader, loss_fn_main, loss_fn_alt, return_preds=False):\n",
    "    model.eval()\n",
    "    total_main = 0\n",
    "    total_alt = 0\n",
    "    preds = []\n",
    "    targets = []\n",
    "    positions_all = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(loader):\n",
    "            data = data.to(device)\n",
    "            out = model(data.x, data.edge_index, data.batch)  # [num_nodes, 1]\n",
    "            y = data.y.view(-1, 1)                            # [num_nodes, 1]\n",
    "\n",
    "            loss_main = loss_fn_main(out, y)\n",
    "            loss_alt = loss_fn_alt(out, y)\n",
    "\n",
    "            total_main += loss_main.item()\n",
    "            total_alt += loss_alt.item()\n",
    "\n",
    "            if return_preds:\n",
    "                preds.append(out.cpu().numpy())\n",
    "                targets.append(y.cpu().numpy())\n",
    "\n",
    "                # Safely collect node positions if available\n",
    "                if hasattr(data, 'pos') and data.pos is not None:\n",
    "                    positions_all.append(data.pos.cpu().numpy())\n",
    "                else:\n",
    "                    print(f\" Skipping positions for batch {i} (data.pos is None)\")\n",
    "\n",
    "    if return_preds:\n",
    "        preds = [p.squeeze() for p in preds]\n",
    "        targets = [t.squeeze() for t in targets]\n",
    "        all_preds_flat = np.concatenate(preds)\n",
    "        all_targets_flat = np.concatenate(targets)\n",
    "        mae = mean_absolute_error(all_targets_flat, all_preds_flat)\n",
    "        corr = np.corrcoef(all_targets_flat, all_preds_flat)[0, 1]\n",
    "\n",
    "        return total_main / len(loader), total_alt / len(loader), mae, corr, preds, targets, positions_all\n",
    "\n",
    "    else:\n",
    "        return total_main / len(loader), total_alt / len(loader)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0482a7e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1849 valid graphs across 7 videos.\n",
      "Using 1294 valid graphs after filtering.\n",
      "Using 277 valid graphs after filtering.\n",
      "Using 278 valid graphs after filtering.\n",
      "Epoch 001 | Train L1: 0.9070 | Huber: 0.6121 || Val L1: 0.1219 | Huber: 0.0176\n",
      "Epoch 002 | Train L1: 0.1534 | Huber: 0.0237 || Val L1: 0.1175 | Huber: 0.0122\n",
      "Epoch 003 | Train L1: 0.1274 | Huber: 0.0166 || Val L1: 0.1177 | Huber: 0.0163\n",
      "Epoch 004 | Train L1: 0.1160 | Huber: 0.0151 || Val L1: 0.1118 | Huber: 0.0134\n",
      "Epoch 005 | Train L1: 0.1106 | Huber: 0.0141 || Val L1: 0.1128 | Huber: 0.0119\n",
      "Epoch 006 | Train L1: 0.1084 | Huber: 0.0136 || Val L1: 0.1093 | Huber: 0.0137\n",
      "Epoch 007 | Train L1: 0.1062 | Huber: 0.0135 || Val L1: 0.1084 | Huber: 0.0130\n",
      "Epoch 008 | Train L1: 0.1057 | Huber: 0.0134 || Val L1: 0.1140 | Huber: 0.0163\n",
      "Epoch 009 | Train L1: 0.1045 | Huber: 0.0131 || Val L1: 0.1106 | Huber: 0.0153\n",
      "Epoch 010 | Train L1: 0.1042 | Huber: 0.0131 || Val L1: 0.1107 | Huber: 0.0150\n",
      "Epoch 011 | Train L1: 0.1036 | Huber: 0.0127 || Val L1: 0.1103 | Huber: 0.0149\n",
      "Epoch 012 | Train L1: 0.1040 | Huber: 0.0130 || Val L1: 0.1082 | Huber: 0.0144\n",
      "Epoch 013 | Train L1: 0.1053 | Huber: 0.0134 || Val L1: 0.1110 | Huber: 0.0141\n",
      "Epoch 014 | Train L1: 0.1033 | Huber: 0.0125 || Val L1: 0.1099 | Huber: 0.0132\n",
      "Epoch 015 | Train L1: 0.1031 | Huber: 0.0122 || Val L1: 0.1108 | Huber: 0.0131\n",
      "Epoch 016 | Train L1: 0.1030 | Huber: 0.0125 || Val L1: 0.1059 | Huber: 0.0116\n",
      "Epoch 017 | Train L1: 0.1032 | Huber: 0.0121 || Val L1: 0.1108 | Huber: 0.0136\n",
      "Epoch 018 | Train L1: 0.1032 | Huber: 0.0126 || Val L1: 0.1061 | Huber: 0.0117\n",
      "Epoch 019 | Train L1: 0.1024 | Huber: 0.0119 || Val L1: 0.1077 | Huber: 0.0151\n",
      "Epoch 020 | Train L1: 0.1029 | Huber: 0.0138 || Val L1: 0.1074 | Huber: 0.0152\n",
      "Epoch 021 | Train L1: 0.1028 | Huber: 0.0139 || Val L1: 0.1061 | Huber: 0.0137\n",
      "Epoch 022 | Train L1: 0.1029 | Huber: 0.0128 || Val L1: 0.1123 | Huber: 0.0145\n",
      "Epoch 023 | Train L1: 0.1023 | Huber: 0.0120 || Val L1: 0.1066 | Huber: 0.0126\n",
      "Epoch 024 | Train L1: 0.1019 | Huber: 0.0116 || Val L1: 0.1071 | Huber: 0.0121\n",
      "Epoch 025 | Train L1: 0.1024 | Huber: 0.0119 || Val L1: 0.1073 | Huber: 0.0120\n",
      "Epoch 026 | Train L1: 0.1019 | Huber: 0.0118 || Val L1: 0.1093 | Huber: 0.0132\n",
      "Early stopping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Platypus\\AppData\\Local\\Temp\\ipykernel_10512\\1713651173.py:54: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"best_baseline_gnn.pt\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Final GNN Test Metrics:\n",
      "  - Test Loss (L1):       0.1087\n",
      "  - Test Loss (Huber):    0.0116\n",
      "  - MAE:                  0.1033\n",
      "  - Pearson Correlation:  0.4105\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    file_paths = [\n",
    "        \"C:/Users/Platypus/Documents/CellNet/Real_Time_CS_Experiment-1093.tif\",\n",
    "        \"C:/Users/Platypus/Documents/CellNet/Flow prior to chemical stimulation_Figure6C.tif\",\n",
    "        \"C:/Users/Platypus/Documents/CellNet/Real_Time_CS_Experiment-1093.tif\",\n",
    "        \"C:/Users/Platypus/Documents/CellNet/Flow prior to chemical stimulation_Figure6C.tif\", #✔ Clicked on Frame 77: (1.16, 2.96); ✔ Clicked on Frame 77: (15.57, 10.86)\n",
    "        \"C:/Users/Platypus/Documents/CellNet/Figure8.tif\",\n",
    "        \"C:/Users/Platypus/Documents/CellNet/5uM_per_litre_Figure6_ChemicalStimulation.tif\",\n",
    "        \"C:/Users/Platypus/Documents/CellNet/Cell Knocked_Figure7.tif\"]\n",
    "\n",
    "    all_graphs = []\n",
    "    for path in file_paths:\n",
    "       # gs = [g for g in build_temporal_graph_sequence(path) if g is not None]\n",
    "        gs = build_temporal_graph_sequence(path)\n",
    "\n",
    "        all_graphs.extend(gs)\n",
    "    \n",
    "    print(f\"Loaded {len(all_graphs)} valid graphs across {len(file_paths)} videos.\")\n",
    "\n",
    "\n",
    "    train_val, test = train_test_split(all_graphs, test_size=0.15, random_state=42)\n",
    "    train_graphs, val_graphs = train_test_split(train_val, test_size=0.176, random_state=42)\n",
    "\n",
    "    train_loader = DataLoader(SimpleGraphDataset(train_graphs), batch_size=1, shuffle=True)\n",
    "    val_loader = DataLoader(SimpleGraphDataset(val_graphs), batch_size=1)\n",
    "    test_loader = DataLoader(SimpleGraphDataset(test), batch_size=1)\n",
    "\n",
    "    model = StrongerGNN(input_dim=train_graphs[0].x.shape[1]).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=CONFIG[\"lr\"])\n",
    "    loss_fn_main = nn.L1Loss()\n",
    "    loss_fn_alt = nn.SmoothL1Loss()  # Huber\n",
    "\n",
    "\n",
    "    best_val_loss = float(\"inf\")\n",
    "    patience_counter = 0\n",
    "\n",
    "    for epoch in range(CONFIG[\"num_epochs\"]):\n",
    "        train_main, train_alt = train(model, train_loader, optimizer, loss_fn_main, loss_fn_alt)\n",
    "        val_main, val_alt = evaluate(model, val_loader, loss_fn_main, loss_fn_alt)\n",
    "\n",
    "        print(f\"Epoch {epoch+1:03} | Train L1: {train_main:.4f} | Huber: {train_alt:.4f} || Val L1: {val_main:.4f} | Huber: {val_alt:.4f}\")\n",
    "\n",
    "        if val_main < best_val_loss:\n",
    "            best_val_loss = val_main\n",
    "            torch.save(model.state_dict(), \"best_baseline_gnn.pt\")\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= CONFIG[\"patience\"]:\n",
    "                print(\"Early stopping.\")\n",
    "                break\n",
    "\n",
    "\n",
    "    model.load_state_dict(torch.load(\"best_baseline_gnn.pt\"))\n",
    "    test_main, test_alt, test_mae, test_corr, preds, targets, positions = evaluate(\n",
    "    model, test_loader, loss_fn_main, loss_fn_alt, return_preds=True\n",
    ")\n",
    "\n",
    "visualize_gnn_predictions(preds, targets, positions, shape=CONFIG[\"resize_shape\"])\n",
    "\n",
    "\n",
    "print(\"\\n✅ Final GNN Test Metrics:\")\n",
    "print(f\"  - Test Loss (L1):       {test_main:.4f}\")\n",
    "print(f\"  - Test Loss (Huber):    {test_alt:.4f}\")\n",
    "print(f\"  - MAE:                  {test_mae:.4f}\")\n",
    "print(f\"  - Pearson Correlation:  {test_corr:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "  \n",
    "    # Love u, \n",
    "    # cmok\n",
    "  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
